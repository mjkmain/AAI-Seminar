{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1ec4f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60d9b741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da15ae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "epoch_num = 15\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f534f03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train_data :  60000\n",
      "number of test_data :  10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\envs\\AAI_2021\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST(root = './data', train = True, download = True,\n",
    "                           transform = transforms.ToTensor())\n",
    "test_data = datasets.MNIST(root = './data', train = False,\n",
    "                          transform = transforms.ToTensor())\n",
    "print('number of train_data : ', len(train_data))\n",
    "print('number of test_data : ', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1d739b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = train_data[0]\n",
    "\n",
    "plt.imshow(image.squeeze().numpy(), cmap = 'gray') #squeeze : 크기가 1인 차원을 없애줌\n",
    "plt.title('label : %s' %label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d9230b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name            | type                      | size\n",
      "Num of batch    |                           | 1200\n",
      "first batch     | <class 'list'>            | 2\n",
      "first batch[0]  | <class 'torch.Tensor'>    | torch.Size([50, 1, 28, 28])\n",
      "first batch[1]  | <class 'torch.Tensor'>    | torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train_data,\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_data,\n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle = True)\n",
    "\n",
    "first_batch = train_loader.__iter__().__next__()\n",
    "print('{:15s} | {:<25s} | {}'.format('name', 'type', 'size'))\n",
    "print('{:15s} | {:<25s} | {}'.format('Num of batch', '', len(train_loader)))\n",
    "print('{:15s} | {:<25s} | {}'.format('first batch', str(type(first_batch)), len(first_batch)))\n",
    "print('{:15s} | {:<25s} | {}'.format('first batch[0]', str(type(first_batch[0])), first_batch[0].shape))\n",
    "print('{:15s} | {:<25s} | {}'.format('first batch[1]', str(type(first_batch[1])), first_batch[1].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41bbaa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module): # nn.Module 클래스를 상속받는 CNN 클래스를 정의\n",
    "    def __init__(self): # __init__를 통해 모델에서 사용되는 가중치를 정의\n",
    "        super(CNN, self).__init__() # supter() 함수를 통해 nn.Module 클래스의 속성을 상속받고 초기화\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1) # in_channels = 1, out_channels = 32, kernel_size = 3, stride = 1\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1) # in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1\n",
    "        self.dropout1 = nn.Dropout2d(0.25) # 0.25확률인 Dropout\n",
    "        self.dropout2 = nn.Dropout2d(0.5) # 0.5 확률인 Dropout\n",
    "        self.fc1 = nn.Linear(9216, 128) # Fully-connected Layer 9216크기인 벡터를 128 크기의 백터로 변환하는 가중치를 설계\n",
    "        self.fc2 = nn.Linear(128, 10) # Mnist의 클래스 개수인 10 크기의 벡터로 변환하는 가중치\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x) # ReLU 활성 함수를 적용. 활성 함수는 단순 연산이므로. __init__에서 정의한 학습 가중치가 없음\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2) # (2x2)크기의 Filter로 Max Pooling을 적용.\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1) # 고차원의 Tensor을 1차원의 벡터로 변환\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim = 1) # 최종 출력값으로 log-softmax를 계산, Softmax함수가 아닌, log_softmax()를 사용 하면 연산속도를 높일 수 있음\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "442f3fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device) # CNN 클래스를 이용해 model이라는 인스턴스를 생성. 코드 상단에 지정한 연산 장비 device를 인식\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate) # Adam 알고리즘의 optimizer를 지정\n",
    "criterion = nn.CrossEntropyLoss() # Cross Entropy를 손실 함수로 지정 - 다중 클래스 분류 문제이기 때문에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d28a4cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5d7630a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Step: 0\tLoss: 0.027\n",
      "Train Step: 1000\tLoss: 0.007\n",
      "Train Step: 2000\tLoss: 0.073\n",
      "Train Step: 3000\tLoss: 0.014\n",
      "Train Step: 4000\tLoss: 0.008\n",
      "Train Step: 5000\tLoss: 0.007\n",
      "Train Step: 6000\tLoss: 0.003\n",
      "Train Step: 7000\tLoss: 0.005\n",
      "Train Step: 8000\tLoss: 0.021\n",
      "Train Step: 9000\tLoss: 0.009\n",
      "Train Step: 10000\tLoss: 0.007\n",
      "Train Step: 11000\tLoss: 0.003\n",
      "Train Step: 12000\tLoss: 0.062\n",
      "Train Step: 13000\tLoss: 0.001\n",
      "Train Step: 14000\tLoss: 0.056\n",
      "Train Step: 15000\tLoss: 0.006\n",
      "Train Step: 16000\tLoss: 0.007\n",
      "Train Step: 17000\tLoss: 0.020\n",
      "141.658825초 걸렸습니다.\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "i = 0\n",
    "import timeit\n",
    " \n",
    "start_time = timeit.default_timer() \n",
    "for epoch in range(epoch_num):\n",
    "    for data, target in train_loader:\n",
    "        data = data.to(device)     # 미니 배치의 데이터를 기존에 지정한 장비 device에 할당\n",
    "        target = target.to(device) # 미니 배치의 정답를 기존에 지정한 장비 device에 할당\n",
    "        optimizer.zero_grad() # 학습을 시작하기 전, 이전 반복 시행에서 저장된 optimizer의 Gradient를 초기화함\n",
    "        output = model(data) # Feed Forward 연산으로 결과값을 계산\n",
    "        loss = criterion(output, target) # 계산된 결과값과 실제 정답으로 손실 함수를 계산\n",
    "        loss.backward() # 손실 함수를 통해 Gradient를 계산\n",
    "        optimizer.step() # 위에서 계산된 Gradient를 통해 모델의 가중치를 업데이트 함\n",
    "        if i % 1000 == 0:\n",
    "            print('Train Step: {}\\tLoss: {:.3f}'.format(i, loss.item()))\n",
    "        i += 1\n",
    "terminate_time = timeit.default_timer()\n",
    "print(\"%f초 걸렸습니다.\" % (terminate_time - start_time)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b6de13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Accuracy: 99.12%\n"
     ]
    }
   ],
   "source": [
    "model.eval() # 평가 모드를 싱행하기 위해 명시. eval() 호출하면, Dropout이 적용되지 않고 Batch-Normalization도 평가 모드로 전환\n",
    "correct = 0\n",
    "for data, target in test_loader:\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    output = model(data)\n",
    "    prediction = output.data.max(1)[1] # Log-Softmax 값이 가장 큰 인덱스를 예측값으로 저장\n",
    "    correct += prediction.eq(target.data).sum() # 실제 정답 예측값이 같으면 True, 다르면 False인 논리값으로 구성된 벡터를 더함.\n",
    "    # 즉, 미니 배치중 정답의 개수를 구하고 반복 시행마다 누적해서 더함\n",
    "    \n",
    "print('Test set: Accuracy: {:.2f}%'.format(100*correct/len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8e9247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
