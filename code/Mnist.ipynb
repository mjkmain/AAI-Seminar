{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e01ee5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn # 딥러닝 네트워크의 기본 요소를 포함한 torhc.nn 모듈\n",
    "import torch.nn.functional as F # 딥러닝에 자주 사용되는 함수가 포함된 모듈 torch.nn.functional\n",
    "import torch.optim as optim # 가중치 추정에 필요한 최적화 알고리즘을 포함한 모듈 torch.optim\n",
    "from torchvision import datasets, transforms # Torchivision 모듈은 딥러닝에서 자주 사용되는  데이터셋과 모델 구조 및\n",
    "# 이미지 변환 기술을 포함하고 있음 그중, datasets, transforms\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e8ffca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current cuda device is cpu\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available() # cuda가 사용할 수 있다면 True 없으면 False\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')\n",
    "\n",
    "print('Current cuda device is', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9e0a47",
   "metadata": {},
   "source": [
    "# 이런 젠장!!! 그래픽 카드가 라이젠이다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdfe87e",
   "metadata": {},
   "source": [
    "## HyperParameter 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c45b4f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50 # 모델 가중치를 한 번 업데이트 시킬 때 사용되는 샘플 단위 개수(=미니 배치 사이즈)\n",
    "epoch_num = 15 # 학습 데이터를 모두 사용하여 학습하는 기본 단위 횟수(=Epoch 수)\n",
    "learning_rate = 0.0001 # 가중치 업데이트 정도(=Learning Rate(학습률))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b0f34a",
   "metadata": {},
   "source": [
    "## MNIST 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95596d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training data:  60000\n",
      "number of test data:  10000\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST(root = './data', train=True, download=True, transform = transforms.ToTensor())\n",
    "test_data = datasets.MNIST(root = './data', train=False,  transform = transforms.ToTensor())\n",
    "\n",
    "print('number of training data: ', len(train_data))\n",
    "print('number of test data: ', len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36211c4",
   "metadata": {},
   "source": [
    "+ train: True/False의 논리값으로 데이터를 학습용으로 사용할 것인지 지정합니다.\n",
    "+ download: True를 입력하면 root 옵션에서 지정된 위치에 데이터가 저장됩니다. 만약 처음 시행이 아니고 이미 저장된 데이터가 있다면, False를 입력합니다\n",
    "+ transform: MNIST 데이터를 저장과 동시에 전처리 할 수 있는 옵션입니다. Pytorch는 입력 데이터로 Tensor를 사용하므로 이미지룰 Tensor로 변형한ㄴ 전처리 transforms.ToTensor()를 사용합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87b61b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = train_data[0]\n",
    "\n",
    "plt.imshow(image.squeeze().numpy(), cmap = 'gray')\n",
    "plt.title('label : %d' %label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39d0b2a",
   "metadata": {},
   "source": [
    "3차원 텐서[1, 28, 28]를 2차원으로 줄이기 위해 image.squeeze()를 사용. squeeze() 함수는 크기가 1인 차원을 없애는 함수로 2차원인 [28, 28]로 만들어 줌."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcd75f9",
   "metadata": {},
   "source": [
    "## 미니 배치 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba042354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name            | type                      | size\n",
      "Num of Batch    |                           | 1200\n",
      "first_batch     | <class 'list'>            | 2\n",
      "first_batch[0]  | <class 'torch.Tensor'>    | torch.Size([50, 1, 28, 28])\n",
      "first_batch[1]  | <class 'torch.Tensor'>    | torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "# torch.utils.data.DataLoader은 손쉽게 배치를 구성하며 학습 과정을 반복 시행할 때마다 미니 배치를 하나씩 불러오는 유용한 함수\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_data,\n",
    "                                           batch_size = batch_size,\n",
    "                                          shuffle = True)\n",
    "test_loadet = torch.utils.data.DataLoader(dataset = test_data,\n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle = True)\n",
    "\n",
    "first_batch = train_loader.__iter__().__next__()\n",
    "print('{:15s} | {:<25s} | {}'.format('name', 'type', 'size'))\n",
    "print('{:15s} | {:<25s} | {}'.format('Num of Batch', '', len(train_loader)))\n",
    "print('{:15s} | {:<25s} | {}'.format('first_batch', str(type(first_batch)), len(first_batch)))\n",
    "print('{:15s} | {:<25s} | {}'.format('first_batch[0]', str(type(first_batch[0])), first_batch[0].shape))\n",
    "print('{:15s} | {:<25s} | {}'.format('first_batch[1]', str(type(first_batch[1])), first_batch[1].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5da632",
   "metadata": {},
   "source": [
    "60,000개의 학습 데이터에 50의 배치 사이즈를 사용했기 때문에 = 12,000개의 미니 배치가 생성\n",
    "미니배치의 첫 번째 요소 first_batch[0]는 [50, 1, 28, 28] 형태의 4차원 Tensor로서, 각 요소는 [Bath Size, Channel, Width, Height]를 나타냄.  \n",
    "first_batch[1]은 50 크기의 벡터로서, 미니 배치의 정답이 저장되어 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf57670",
   "metadata": {},
   "source": [
    "## CNN 구조 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afac7c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module): # nn.Module 클래스를 상속받는 CNN 클래스를 정의\n",
    "    def __init__(self): # __init__를 통해 모델에서 사용되는 가중치를 정의\n",
    "        super(CNN, self).__init__() # supter() 함수를 통해 nn.Module 클래스의 속성을 상속받고 초기화\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1) # in_channels = 1, out_channels = 32, kernel_size = 3, stride = 1\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1) # in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1\n",
    "        self.dropout1 = nn.Dropout2d(0.25) # 0.25확률인 Dropout\n",
    "        self.dropout2 = nn.Dropout2d(0.5) # 0.5 확률인 Dropout\n",
    "        self.fc1 = nn.Linear(9216, 128) # Fully-connected Layer 9216크기인 벡터를 128 크기의 백터로 변환하는 가중치를 설계\n",
    "        self.fc2 = nn.Linear(128, 10) # Mnist의 클래스 개수인 10 크기의 벡터로 변환하는 가중치\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x) # ReLU 활성 함수를 적용. 활성 함수는 단순 연산이므로. __init__에서 정의한 학습 가중치가 없음\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2) # (2x2)크기의 Filter로 Max Pooling을 적용.\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1) # 고차원의 Tensor을 1차원의 벡터로 변환\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim = 1) # 최종 출력값으로 log-softmax를 계산, Softmax함수가 아닌, log_softmax()를 사용 하면 연산속도를 높일 수 있음\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eb0aab",
   "metadata": {},
   "source": [
    "## Optimizer 및 손실 함수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6117338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device) # CNN 클래스를 이용해 model이라는 인스턴스를 생성. 코드 상단에 지정한 연산 장비 device를 인식\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate) # Adam 알고리즘의 optimizer를 지정\n",
    "criterion = nn.CrossEntropyLoss() # Cross Entropy를 손실 함수로 지정 - 다중 클래스 분류 문제이기 때문에"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669dd919",
   "metadata": {},
   "source": [
    "## 설계한 CNN 모형 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b07dd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba5d014",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f97cb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Step: 0\tLoss: 2.309\n",
      "Train Step: 1000\tLoss: 0.200\n",
      "Train Step: 2000\tLoss: 0.217\n",
      "Train Step: 3000\tLoss: 0.058\n",
      "Train Step: 4000\tLoss: 0.292\n",
      "Train Step: 5000\tLoss: 0.088\n",
      "Train Step: 6000\tLoss: 0.053\n",
      "Train Step: 7000\tLoss: 0.050\n",
      "Train Step: 8000\tLoss: 0.209\n",
      "Train Step: 9000\tLoss: 0.011\n",
      "Train Step: 10000\tLoss: 0.017\n",
      "Train Step: 11000\tLoss: 0.008\n",
      "Train Step: 12000\tLoss: 0.003\n",
      "Train Step: 13000\tLoss: 0.010\n",
      "Train Step: 14000\tLoss: 0.135\n",
      "Train Step: 15000\tLoss: 0.028\n",
      "Train Step: 16000\tLoss: 0.201\n",
      "Train Step: 17000\tLoss: 0.012\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "i = 0\n",
    "for epoch in range(epoch_num):\n",
    "    for data, target in train_loader:\n",
    "        data = data.to(device)     # 미니 배치의 데이터를 기존에 지정한 장비 device에 할당\n",
    "        target = target.to(device) # 미니 배치의 정답를 기존에 지정한 장비 device에 할당\n",
    "        optimizer.zero_grad() # 학습을 시작하기 전, 이전 반복 시행에서 저장된 optimizer의 Gradient를 초기화함\n",
    "        output = model(data) # Feed Forward 연산으로 결과값을 계산\n",
    "        loss = criterion(output, target) # 계산된 결과값과 실제 정답으로 손실 함수를 계산\n",
    "        loss.backward() # 손실 함수를 통해 Gradient를 계산\n",
    "        optimizer.step() # 위에서 계산된 Gradient를 통해 모델의 가중치를 업데이트 함\n",
    "        if i % 1000 == 0:\n",
    "            print('Train Step: {}\\tLoss: {:.3f}'.format(i, loss.item()))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b0ebc3",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d10ae87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "model.eval() # 평가 모드를 싱행하기 위해 명시. eval() 호출하면, Dropout이 적용되지 않고 Batch-Normalization도 평가 모드로 전환\n",
    "correct = 0\n",
    "for data, target in test_loadet:\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    output = model(data)\n",
    "    prediction += output.data.max(1)[1] # Log-Softmax 값이 가장 큰 인덱스를 예측값으로 저장\n",
    "    correct += prediction.eq(target.data).sum() # 실제 정답 예측값이 같으면 True, 다르면 False인 논리값으로 구성된 벡터를 더함.\n",
    "    # 즉, 미니 배치중 정답의 개수를 구하고 반복 시행마다 누적해서 더함\n",
    "    \n",
    "print('Test set: Accuracy: {:.2f}%'.format(100*correct/len(test_loadet.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687da314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
